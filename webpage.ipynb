{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01be0497",
   "metadata": {},
   "source": [
    "## 1.1. Fitting a voxel grid\n",
    "\n",
    "![aaa](q1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8b367",
   "metadata": {},
   "source": [
    "## 1.2. Fitting a point cloud \n",
    "\n",
    "![bbb](q1-2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0127fb",
   "metadata": {},
   "source": [
    "## 1.3. Fitting a mesh\n",
    "\n",
    "![ii](q1-3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eef0cf",
   "metadata": {},
   "source": [
    "## 2.1. Image to voxel grid\n",
    "\n",
    "![1](./vis/0_vox.gif)\n",
    "![2](./vis/400_vox.gif)\n",
    "![3](./vis/600_vox.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9eb7a",
   "metadata": {},
   "source": [
    "## 2.2. Image to point cloud\n",
    "\n",
    "![1](./vis/0_points.gif)\n",
    "![2](./vis/400_points.gif)\n",
    "![3](./vis/600_points.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c026e7",
   "metadata": {},
   "source": [
    "## 2.3. Image to mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c545bc1",
   "metadata": {},
   "source": [
    "## 2.4. Quantitative comparisions\n",
    "\n",
    "| Type        | F1@0.05 |\n",
    "|-------------|---------|\n",
    "| Voxel       | 71.996  |\n",
    "| Point Cloud | 78.989  |\n",
    "| Mesh        |         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c5667",
   "metadata": {},
   "source": [
    "## 2.5. Analyse effects of hyperparams variations\n",
    "\n",
    "- Voxel size: When decreasing the voxel size from 32 to 16, the performance degrades-F1@0.05 drops from 72 to 65.5. Finer details are missing, e.g., the thin legs of the chair disappear.\n",
    "\n",
    "- number of points: Increasing the number of points can cause a more robust training, the F1@0.05 improving from 78.989 to 82.740.\n",
    "- w_smooth:\n",
    "- initial mesh:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad7d4b",
   "metadata": {},
   "source": [
    "## 2.6. Interpret your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f81f64",
   "metadata": {},
   "source": [
    "## 3.1 Implicit network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c82d1",
   "metadata": {},
   "source": [
    "## 3.2 Parametric network\n",
    "\n",
    "The image to points model in 2.2 use an AtlasNet like model that takes the global latent vector and a 2d point as input, the point coordinate is transform from dim=2 to dim=512 with a linear function then add to the global latent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce88567",
   "metadata": {},
   "source": [
    "## 3.3 Extended dataset for training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
